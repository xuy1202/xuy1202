<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[PDNS系统设计实现总结]]></title>
      <url>%2F2017%2F03%2F13%2Fpdns-process-notes%2F</url>
      <content type="text"><![CDATA[从14年中开始，我们团队开始做中国最大的PassiveDNS系统，并在基本的PDNS系统之上，衍生了很多的额外的功能服务。当前我们有: flint: 基本的passive dns系统，domain-ip ip-domain的映射关系的历史记录查询. passivedns.cn，只对安全公司可信分析人员开放 flint.real: flint是所有历史记录的数据，这个flint.real则是最近一小时内的domain-ip/ip-domain的映射关系，数据实时分析的时候，实时的关系更重要 domain_stat: 域名访问统计，可以区分不同的请求类型，不同的返回类型，不同的数据节点 domain_access/client_access: 查询一段时间内，一个domain被哪些client访问，一个client都访问了哪些domain，交叉访问的记录数据 profile_domain/profile_client/profile_dnserv: domain/client/dnserv的profile数据，比如一个域名在一个时间点，被谁访问，来自哪些原端口，tid分别是多少，请求类型的分布是如何，返回的数据是如何分布的，响应这个domain 的dnserv都有哪些等等。在此基础上，可以实时判定诸如RSD攻击，子域名爆破，反射放大等各种安全事件 pdns_capture: 给定过滤条件，实时抓取最新的DNS记录数据 dtree：域名查找服务，给定一个模式，可以是子域名，可以是wildcard，可以是正则表达式，快速的在所有FQDN中查找符合模式的域名。很多安全分析文章都会对敏感域名打码，对我们而言，几乎天下无码。 这是我在当前团队做的第一个服务，2年多来也一直在改进维护，除了前端接入原始数据是同事在做，中间的数据流，处理分析，入库，查询接口，都是我在做。其中艰辛很多，也感觉学到很多，资源不够如何权衡妥协，网络不如意服务如何调度分派，数据放量如何动态扩展，很多细节如果不看代码都要忘记了。刚好年初数据放量，重新梳理代码优化了一下性能，趁机聊作记录以备忘。 出于保密的需求，具体架构不能说太细，数据库设计不会涉及，更多的是偏重功能+场景+实现妥协技巧这些容易遗忘的东西 数据采集点的区别数据分析的前提是要懂数据，懂数据的前提就是要知道数据从哪来，是什么样子的，从而可以知道对于得到的数据，那些能做，哪些不能做。不同的采集点，采集到的数据不一样，量有大小的区别，覆盖范围有区别，可以提取出来的特征不一样，因此对于既定的分析目标，可能一个采集点的数据可以轻而易举的完成，而另外一个采集点可能做起来会非常费力，甚或天然的就无法做到。 由于懒，我直接抠我在FloCon2017上的talk的PPT的一页来说明。 上图是一个最简单的DNS请求的全路径。一个用户在运营商提供的一个子网内，发起的DNS请求通过运营商的边界路由，到一个OpenResolver/RecursiveServer，OpenResolver/RecursiveServer 负责完整的递归查询，将最终的IP返回给用户 open resolver 之上图中的点【1】处。 这里的数据是DNS服务商的递归查询数据。理论上，只有当 一个查询的域名之前没有查询过 一个已经缓存的域名结果TTL已经过期 两种情况下，才会有递归数据产生。 域名的请求永远是大头长尾的数据形态，大部分的查询都会落在缓存中，有效的TTL时间范围内，一般来说，这里的数据量比点【2】处的客户端查询要小2个数量级。 加之一般的DNS服务商都会有基本的数据过滤，不合法的请求，错误的数据包，基本都可以很轻松的清洗掉，所以这里的数据也会比较干净。 数据量小，而且干净，拥有所有的递归过程的数据，因此这里的数据最适合用于构建一个PDNS系统，用以记录历史上domain-ip的映射关系及其变化。 open resolver 之下图中的点【2】处。 这里的数据包括所有的点【1】的数据，不过数据量至少至少上升了2个数量级。 此外，在这里我们看得到客户端的数据，我们可以知道一个client ip在什么时间请求了什么域名。一个client ip频繁的请求比如cpsc.gov ANY，这极有可能是反射放大。一个client ip请求同一个SLD的不同的子域名，这又分至少两种情况：子域名如果构成比较规律，比如一个单词，那可能是子域名暴力破解；子域名如果构成是杂乱的随机字符串，那可能是RSD攻击。 而且，我们在此还可以知道query数据包中的src port（sport），transaction id（tid）数据。真实的DNS请求都是伴随着随机的sport/tid，因此，在一段时间内，针对同一个domain的所有query，或者一个client发出去的针对任意domain的query，其sport/tid的统计肯定是离散的，当统计显示针对某domain／某client的sport/tid是聚集的时候，我们就有相当大的把握断定这部分数据是伪造的query。 路由器边界图中的点【3】处。 乍看起来，点【3】的数据等于把所有点【2】的数据都汇聚到一起。现实的问题在于：1）点【2】的数据都属于各大DNS厂商，这部分数据不可能完全汇总分享 2）正常的用户往往都会使用一个DNS服务器，但是和DNS相关的攻击流量都会和很多的open resolver相关 3）有很多DNS流量和open resolver无关，在点【2】也看不到，因此点【3】是非常必要的。 举例来说，RSD攻击一般来说会通过多个open resolver来打，但是也可能伪造流量直接请求到authoritative server，如果是后者，那在点【2】的位置就完全看不到，但是在点【3】可以看到。 再者，点【3】是client-focused，比如反射放大攻击，一次攻击可能动用上万个open resolver，在点【2】的单个open resolver处很可能被忽略掉，但是点【3】看到的是一个client ip接受来自上万个open resolver的响应，想故意漏掉都比较难吧。 甚或，这里我们可以看到query without response 有去无回数据, response without query无中生有数据，看到一个DNS服务器将任意domain的query响应为一个固定的IP等等，具体有什么用，think～ 其他上述三个数据采集点是做DNS数据分析一般的，常规的，最有效的数据采集位置。 我们很富，我们都有 。此外前后两端的数据采集点也要注意。 authority server 边界麻烦各个NS管理员，如果闲了，看看自己的DNS服务器处理的请求都是什么，有没有开泛解析，有没有配置错误将一个权威服务器开启了递归查询功能。我们的数据表明，常被利用的DNS反射节点中，至少2%是开了递归查询功能的权威服务器，无意间就给反射放大攻击添柴助力。 客户端网卡说一个场景，用户电脑，没人操作的时候，恶意软件可没闲着，各种可疑的黑网站，DGA这时候都会突兀的出现。 不可说实际上，任何可以获取DNS解析记录的地方，其数据可能都有独到可用之处。尤其考虑到数据获取的场景context，简单来说，场景越黑，数据越黑。你有黑场景的数据可分享么？如果有，请联系我～ 接入点处理当前我们的数据在白天忙时平均有700w records/s，record指得是query-response pairing之后提取出来的数据记录。多个数据节点数据并不是平均分配的，最大的点超过150w/s，接入的千兆网卡是打满的状态。针对这么大的数据量，系统架构，或者说数据流设计，都要依赖一个高效稳固的接入和足够灵活的数据分发方式，所以接入点的处理单独拎出来说明一下。 sensor：负责原始DNS流量的抓取，解析，配对过程，形成最终的record，然后以hash(client ip/24)为key将数据publish出来 hasher：接受从sensor的record数据，然后以hash(SLD)的形式将数据publish出来 考虑到用户隐私，client ip可以做混淆 应对超大量数据 数据水平切分，client／domain两大维度，后续详细分析 传输使用Zmq，pub/sub模式，单ctx足够 数据格式为protobuf。另：注意所有字段都为optional，不明白原因的去google 批量合并压缩数据，zlib的Z_BEST_SPEED模式下压缩率为30%左右 无锁队列，zmq的push/pull (inproc://addr)。注意，一定是消费者同质的时候才可以。消费者不同质，老老实实上lock-queue，否则一个慢消费者会拖死整个队列 log要异步多线程flush 打点统计尽可能避免锁，可以使用__sync_XXX系列函数，也可以考虑thread::local单独打点，合并dump 数据分割这一点尤为关键，接入的数据量巨大，不可能根据不同的需求重复传输多次，只有水平切分做好，后续的处理过程才能非常方便的扩展。 我的架构里，sensor和hasher作为公共的数据获取接口，其中sensor是以hash(client ip)为key的获取接口，hasher是以hash(SLD)为key的获取接口。 根据需求，如果后续的分析过程是以domain为核心的，那就从hasher来获取，所有*.test.domain都会被分发到一个同一个key下。如果想看某个client ip的情况，那就从sensor直接获取，那同一个client ip的访问行为会集中发布在同一个key上。 提取SLD的过程，不要简单的从后向前数点，com.cn等多级的TLD和com等单级的TLD判断起来会比较麻烦费力。先将所有TLD数据load成为一个trie tree，来的每一条数据，将FQDN从后向前遍历到最深，然后接着遍历到结尾或者下一个.的位置即可，考虑到SLD的长度基本都会在10个字符以内，这样的算法可以认为是O(1)的。 LRU 去重DNS原始请求按照域名来看 永远是大头长尾 的数据形态，top 100网站的访问量占据了所有访问请求的半壁江山，因此一个放置在足够靠前位置的LRU cache，就可以有效的对大头数据进行去重缩量。一个百万size的大小的cache，可以将原始数据缩减一个数量级。 Disposable domain处理过程的数据量缩减了就OK了么？NO。当前，DNS服务被滥用的非常厉害，很多的域名查询已经不是原始的domain-ip映射关系的作用，有的用来做数据上报，有的用来做request-response服务，还有更多的不知道在干什么。例如： 12345678910111213141516171819202122232425262728293031323334353637141.131.152.01.zen.spamhaus.org128.185.146.01.zen.spamhaus.org161.101.124.01.zen.spamhaus.org125.166.112.01.zen.spamhaus.org112.147.171.01.zen.spamhaus.org187.115.108.01.zen.spamhaus.org115.118.145.01.zen.spamhaus.org145.119.155.01.zen.spamhaus.org2az8s49ydcfmtjk.q13795113801.pw2iu5dsf679glqjp.q13795113801.pw2icpazfdh3ewl59.q13795113801.pw298gc7pfdy5a6jh.q13795113801.pw29oiqrcle3ymg4u.q13795113801.pw243twlvqkovhmye.q13795113801.pw28xmi5p63gskjr9.q13795113801.pw27n8pqgihzl6ts9.q13795113801.pw257dsqmhzvx3n8w.q13795113801.pw27lvywg4t8eocm3.q13795113801.pw0.209d801.1033.14b4.15c2.3e9b.10.0.00c674b565ce48ea12966d1b82b66522.avqs.mcafee.com0.60ab089.41.14b4.15c2.3e9b.10.0.087321142026ece602c83ab04528010c.avqs.mcafee.com0.7092081.d960073.14b4.15b4.3e9a.10.0.09f2c55b594c11a6562f932ce8654ef0.avqs.mcafee.com0.7091081.1033.14b4.15b4.3e9a.10.0.05441f6ba15c1f633a3968332fe9b9a9.avqs.mcafee.com0.400001.d960073.14b4.15a2.3e9a.10.0.0c44e2b096e7c988856103b74d5b4766.avqs.mcafee.com0.60fa021.c871031.14b4.15b4.3e9a.10.0.0ac236f269070480252be0b92f545d59.avqs.mcafee.com0.70f6801.c051031.14b4.15e0.3e9a.10.0.0c406d44050caac10e17eaa6c33e1f4f.avqs.mcafee.com0.70f2008.20033.14b4.15b4.3e9a.10.0.10a2f663fdc511fd52bfcfd0a8837549.avqs.mcafee.comx-0.19-23000809.0.16a8.1ff0.6592.200.0.1113g9hwlzvrnims8qbe2ublbi.avqs.mcafee.comx-0.19-23000809.0.16a8.1fcd.6592.200.0.1113g9hwlzvrnims8qbe2ublbi.avqs.mcafee.com123456789123456789.3218721830764663770520984289166039746476607721908141260485540.5020666520264355071788964119716022440607979911188348837802609.11111111111111111111111111111111111111111111111111111111111111.top123456789123456789.3218721830764663770520984289166039746476607721908141260485540.5020666520264355071788964119716022440607979911188348837802609.11111111111111111111111111111111111111111111111111111111111111.topwww.123456789123456789.3218721830764663770520984289166039746476607721908141260485540.5020666520264355071788964119716022440607979911188348837802609.11111111111111111111111111111111111111111111111111111111111111.top02609.11111111111111111111111111111111111111111111111111111111111111.top123456789123456789.3218721830764663770520984289166039746476607721908141260485540.5020666520264355071788964119716022440607979911188348837802609.11111111111111111111111111111111111111111111111111111111111111.top 这种“用一次就丢的”域名，可能已经不属于我们想要的domain-ip mapping关系，不在我们想要分析的范围内。现实中，尽管他们占据所有原始请求数据的比例不高，远远比不上top domain的请求量，但是如果按照unique(FQDN)来统计，这些类型的FQDN至少占据了最终入库的70%（刚随手统计了我们新增域名最近一个月的数据。也就是说，这部分数据可能不会对实时处理过程有严重影响，但是对最终的数据集的大小影响比较大。 因此，我们可以选择一个合适的环节丢弃；即便不全部丢弃，也可以采样来降低数据集大小；或者选择性丢弃，只保留例如spamhaus结果为黑的部分。 “阶梯”采样但是，并不是所有处理环节都能使用LRU 去重，比如我要统计请求一个特定域名的客户端的分布的时候; 也并不是所有环节都能干掉disposable domain，比如我想看一个client ip都访问了哪些域名的时候。 以前者为例，此时要分析的数据中心就是一个域名，client ip是作为属性存在的，如果全部记录，数据量会非常庞大，但是如果针对全局数据采样，那可能长尾数据就被采丢了，而大头还是大头。正确的做法是，针对要分析的key，domain，对其属性进行采样，例如100个以内的client ip全记录, 100-1000个的时候只记录1/10， 1000个往上只记录1/100。这样，长尾数据会被完好的保留下来，而大头数据会被有效缩减，且能保留它的统计特征。 基本架构／数据流PDNS system从hasher开始，接入LRU cache做去重(deduper)，然后 cached_count_limit cached_times_limit 两个判定条件将数据pop out(worker)，最终入库 rrset／rdata real-time data query system从hasher开始，接入去掉disposable domain的数据，a.baidu.com -&gt; com.baidu.a .分割，类似trie tree的结构遍历节点存储count(stater)5分钟为时间单位，遍历count tree，把结果入库，形成domain的访问统计 cross-access system从stater开始，以domain为key对client阶梯采样，可以查询一个client在给定时间都访问过哪些域名，也可以查询一个域名在给定时间都被哪些client访问 real-time analysis system从stater开始，分别对domain/client ip/dns server进行建模统计，实时检测DGA-client, DNS反射放大攻击， RSD攻击，子域名暴力破解等等异常行为 dtreedtree存在的意义就是天下无码，这里所有disposable domain都可以去掉。当前我们dtree集群加载数据为百亿FQDN，加上时间类型等基本信息，文件为500G大小，新的FQDN除去disposable domain外产生的速度比较慢，因此这部分数据还是允许都加载到内存的。 实时分析处理Points归一化及数据预处理 大小写归一化 域名合法性判定，有返回结果的不一定是好域名, 不符合域名规范的也可能是真实使用的域名 rdata排序 response error判定，比如被sinkhole的域名，比如本来是NXDOMAIN但是返回一个劫持IP等情况 Profile[domain/client/dnserv]特征越全越好，参考上面不同采集点的数据特点，可利用的数据属性也不一致，不过domain/client/dnserv尽管是不同维度，但是在同样的数据采集点，特征大部分还是相似的。 Profile的意义不仅仅是可以直接判断各种异常，而更重要的意义是做为history snapshot，可以为后续的判断提供证据基础。 特征选择特征除了原始数据，一定要尽可能泛化，len／top／avg／diss／sequ／compose／pattern 各个维度的统计数据在特定场景下可以发挥决定性的作用。 随机程度的度量：熵？域名随机性往往都喜欢用熵来做，不过我觉得不好。 域名的作用本意是为了好记，正规的域名往往都是英文单词／词根／拼音／惯用简写的组合，看到一个随机字母的或者数字的，不是dga就是赌博色情这种常常变化的，那为什么不直接来判断域名的组合特征？ 所以，做个分词器，动态加载不同的词表就能做各种组合的判断了。拼音就那么几百个，英文词根也很少，单词不要用词典，去搜索一个google top words就很好用了，里面还包含常用的缩略语。一个比较长的串，可能会有多种组合形式，选择的时候，优选覆盖原始字串最长的，次选组合成分最少的，几乎就没错了。 匆匆忙忙，蜻蜓点水，权作备忘。 一个一个子系统的做过来没什么感觉，回顾的时候发现要想写一个全景的流程图PPT都写不下，任何一个子系统的工程实践，几乎都有意料之外的约束。计算机艺术是妥协的艺术，满足了需求的就是好的。 立志成为低碳程序员的我，相当一部分成就感就是来自于“只加需求，不加机器”。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用[hexo + github + next]来构建个人博客]]></title>
      <url>%2F2017%2F03%2F11%2Fhexo-github-blog%2F</url>
      <content type="text"><![CDATA[博客已经过时许久，不过我年纪渐长，记性渐差，还是需要个这么个东西来记录。之前blog是在自己的vps，不过时不时被gfw干掉，操作不便，学习了下当今潮流，发现hexo+github+next半天就可以搞定，而且足够满足我的需求，于是搞起。 hexo；一个基于node的静态博客生成发布引擎，简单来说，就是用户只用写markdown的文稿，后续生成页面、渲染、发布的过程都由hexo来搞定的 github：实际是github的page，静态博客的载体，hexo会将内容发布到用户自己github的page，然后通过page来查看。如果有自己的域名，也可以cname到自己的github的page，这样就能通过自己的域名来访问。 next：只是依赖hexo框架的一个主题样式，比较漂亮，而且还提供根据markdown的标题自动生成outline等辅助功能。 hexo的环境配置直接贴脚本 12345678910111213141516171819202122232425262728293031mkdir your.dircd your.dirnpm install hexo-cli --savenpm install hexo --savehexo initnpm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --savenpm install hexo-util --savenpm install hexo-generator-searchdb --savegit clone https://github.com/iissnan/hexo-theme-next themes/nextcd themes/nextnpm installnpm install -g bowernpm install -g grunt-clicd - 此时，如果所有安装都没有意外，执行 hexo server 就可以启动http服务器在本机4000端口，有一个默认的hello world的主页面 省略github的配置以及github page的部署过程省略自己域名 到 github page的映射过程hexo 配置两个配置文件：1, yourdir/_config.yml: 这个是hexo的配置文件，包括使用哪个主题，这里我们使用next，就需要在该配置中设置。同时，还需要在这里配置要同步到的github page的地址。2, yourdir/themes/next/_config.yml: 这个是主题相关的配置，包括页面布局，第三方评论统计接口等等，看看就明白了3, 我的配置参见：https://github.com/xuy1202/blog 注意： hexo deploy 的时候，是从source文件夹生成为public，然后上传到github。而自己的域名绑定到xxx.github.io的时候，xxx.github.io下面第一级必须有一个CNAME文件对应为自己的域名。所以，必须将对应的CNAME文件放到source一份，这样才能保证每次deploy之后，从自己域名转到github的访问是正确的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[C++ Tail Call Optimization]]></title>
      <url>%2F2017%2F03%2F09%2FC-Tail-Call-Optimization%2F</url>
      <content type="text"><![CDATA[一直没有验证过C++对尾递归的优化，同事讨论起来，写个代码验证下 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;unistd.h&gt;int tailrecsum(int x, int&amp; running_total)&#123; if(x == 0)&#123; return running_total; &#125; usleep(100); // GOOD running_total += x; return tailrecsum(x - 1, running_total); // BAAD //return x + tailrecsum(x - 1, running_total);&#125;int main(void)&#123; int r = 0; std::cout &lt;&lt; tailrecsum(10 , r) &lt;&lt; std::endl; std::cout &lt;&lt; tailrecsum(100 , r) &lt;&lt; std::endl; std::cout &lt;&lt; tailrecsum(1000 , r) &lt;&lt; std::endl; std::cout &lt;&lt; tailrecsum(10000 , r) &lt;&lt; std::endl; std::cout &lt;&lt; tailrecsum(100000 , r) &lt;&lt; std::endl; std::cout &lt;&lt; tailrecsum(2000000000, r) &lt;&lt; std::endl; return 0;&#125; 上述代码，GOOD的两行就是尾递归模式，BAAD的一行是普通递归的模式如果把usleep睡眠屏蔽，直接g++编译，执行立马会 “Segmentation fault: 11”把usleep放开，会观察到内存持续上升，这就是栈调用占用的内存 但是只要开启了 -O1/2/3 优化模式编译，把usleep屏蔽掉，结果会很快返回（当然，结果是错的，溢出成负数）。把usleep放开，可以观察到内存会恒定不变，此时递归调用不会随着调用过程占用额外的内存。 如果是BAAD的代码，-O1/2/3 编译也是没用的。 结论： 编译器能够针对尾递归代码进行执行优化，此时递归调用基本相当于一个循环，前提是要 -O1/2/3 开启编译优化 编译器不会把非尾递归的代码优化成尾递归的效果，绿色低碳程序员请多留心，提高自己姿势水平，代码一小行，烧掉一棵树]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[FloCon 2017]]></title>
      <url>%2F2017%2F01%2F15%2FFloCon-2017%2F</url>
      <content type="text"><![CDATA[Here is the slide of my talk on FloCon 2017. DOWNLOAD: Backbone Network DRDoS Attack Monitoring and Analysis.pdf DRDoS accounts for over 60% of all DDoS, hard to track, annoying bandwidth consumption, larger &amp; larger DNS ＋ NTP ＋ CharGEN reflection account for over 77% of all DRDoS events DRDoS amplifiers has been bing used heavily, over 30% of our detected DNS amplifiers are bing used for DRDoS right now DNS reflection using ANY query, NTP reflection using MONLIST command, CharGEN …, all of little practical use Kill top amplifiers’ in-traffic, solve the majority problem, no effect to normal network, hands together, let’s DO it. Happy time at San Diego.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Security Bsides Delaware 2016]]></title>
      <url>%2F2016%2F10%2F16%2FSecurity-Bsides-Delaware-2016%2F</url>
      <content type="text"><![CDATA[Here is the slide of my talk on Security Bsides Delaware 2017. DOWNLOAD: Backbone Network Security Visibility In Practice.pdf]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[c++ 通过 frind 来获取一个类的 private 成员变量]]></title>
      <url>%2F2015%2F03%2F16%2Fc-frind-get-private-value%2F</url>
      <content type="text"><![CDATA[有个朋友问到一个给定的不可变的类，且是安装好的三方库，不能改代码，不能重新编译，想获取其私有变量，有什么方法？答案是友元～ lib头文件 t.h12345678910#include &lt;iostream&gt;class P&#123; private: std::string private_string; public: P(); //friend class G; // ADD THIS LINE&#125;; lib代码 t.cc1234#include "t.h"P::P():private_string("private_string")&#123;&#125; 上面两个文件编译为libt。注意这时候上面friend是屏蔽掉的，因为我们假定原始给定的头文件没有友元。12[xuamao@xuamaos-MacBook-Pro:~/qdev/test]$ g++ -c -fPIC t.cc -o t.o[xuamao@xuamaos-MacBook-Pro:~/qdev/test]$ g++ -shared -o libt.so t.o 我们自己的测试代码m.cc1234567891011121314151617#include "t.h"struct G&#123; std::string get_private(const P&amp; p) &#123; return p.private_string; &#125;&#125;;int main(void)&#123; P p; G g; std::cout &lt;&lt; g.get_private(p) &lt;&lt; std::endl; return 0;&#125; 此时如果不把上述friend行打开，直接编译会报错：12345678[xuamao@xuamaos-MacBook-Pro:~/qdev/test]$ g++ m.cc -lt -L./m.cc:6:18: error: 'private_string' is a private member of 'P' return p.private_string; ^./t.h:5:21: note: declared private here std::string private_string; ^1 error generated. 这是符合预期的，因为就是要测试friend行代码的效用嘛～打开后就能正常编译执行。我的测试环境是mac+clang，如果是linux＋g++，最后编译可执行文件时需要增加运行期lib查找路径 -Wl,-rpath=./ 总结： class的private/protected权限是编译期的行为，提供的是编译期的内存获取权限的检查，编译完成后就没有任何约束了 因此，我们想要获取一个给定对象的私有变量，是我们自己代码编译时期的权限检查，只要保证自己代码编译时有friend来放开权限即可 如果给定一个类，对于其私有成员变量，直接get有时候可以理解，绝不要直接set，在不知道原本class实现的前提下，极有可能会破坏其内部实现的逻辑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[劫持tshark使其更方便的和我们自有系统交互]]></title>
      <url>%2F2015%2F03%2F11%2Fwireshark-tshark-hijack%2F</url>
      <content type="text"><![CDATA[劫持tshark解包接口 wireshark是一款伟大的工具，tshark是wireshark的命令行工具，具有丰富的功能。但是tshark只能将数据包抓取解析并按照既定格式打印出来，没办法做更自由的数据格式，比如把特定数据形成Porotobuf格式，也没法对外交互，比如发送到某个socket等。 So，let‘s make it. 简单说一下环境： Centos6 wireshark-1.10.8 源码 要劫持接口，那就追代码，hark源码的结构可以在其他地方找到更详细的剖析，我们只需要知道以下几个点： 各种协议包的解析在wireshark-1.10.8/epan/dissectors/ 下面 根据协议解包是个顺序的调用的过程，比如epan/dissectors/packet-ip.c中解析完IP协议，然后调用epan/dissectors/packet-udp.c来解析UDP协议，依次往后，直至没有新协议数据需要解析为止 协议包数据解析完是一个proto_tree结构，这棵树的添加构造在epan/proto.c中，上面的dissector都会掉用proto.c中的方法来将解析出来的数据添加到树中 注意一个header_field_info结构，内部成员name是展示的名字， abbrev是解析包过程中用到的过滤名字，比如ip.src udp.dstport等，还有一个type标识对应的value应该是什么数据 proto.c设置数据的时候，会调用5个基本类型的数据设置方法 fvalue_set fvalue_set_sinteger fvalue_set_uinteger fvalue_set_integer64 fvalue_set_floating，代码在epan/ftypes/ftypes.c 数据流收缩的最小的口径就是在ftypes.c中，从这里入手才能最小代码的改动来劫持到所有数据。但是这里的函数获取到的只有value，而我们需要key和value都能一一对应上，因此还需要在调用者proto.c上动点手脚。 方法1 创建如下文件shark_hijack.h 123456789101112131415161718192021222324252627282930313233343536373839404142void hijack_call(field_info *fi)&#123; if(! fi) return; const char* finfo_name = fi-&gt;hfinfo-&gt;name; const char* finfo_abbrev = fi-&gt;hfinfo-&gt;abbrev; int finfo_type = (fi-&gt;hfinfo) ? fi-&gt;hfinfo-&gt;type : FT_NONE; switch (finfo_type) &#123; // do your work here, you can get setted value like: // fvalue_get(&amp;fi-&gt;value) &#125; return;&#125;#define fvalue_set(i ...) do&#123; \ fvalue_set(i); \ hijack_call(fi); \&#125;while(0) \#define fvalue_set_uinteger(i ...) do&#123; \ fvalue_set_uinteger(i); \ hijack_call(fi); \&#125;while(0) \#define fvalue_set_sinteger(i ...) do&#123; \ fvalue_set_sinteger(i); \ hijack_call(fi); \&#125;while(0) \#define fvalue_set_integer64(i ...) do&#123; \ fvalue_set_integer64(i); \ hijack_call(fi); \&#125;while(0) \#define fvalue_set_floating(i ...) do&#123; \ fvalue_set_floating(i); \ hijack_call(fi); \&#125;while(0) \ 将上述文件放在epan/ftypes/文件夹下，然后在epan/proto.c原文件最后一行include之后添加，如下行 1#include "ftypes/shark_hijack.h" 这样，将原始的5个设置方法以宏的形式替换，在原始操作之后，调用hijack_call，将整个field_info指针传递过去，这里我们就能获取到name abbrev value，就可以根据自己的需求做些想做的事情了。这样的完整的样例可以在 https://github.com/xuy1202/xylibs/tree/master/tshark_wrap 看到 方法2上面的方法最简单，但是需要在hijack_call中做类型判断，我们可以将修改面扩大一点，但是整体上更简单 将上述shark_hijack.h修改为如下，还是用宏劫持的方式 123456789101112131415161718192021222324252627282930void shark_id_dispatch_string(int id, const char* val);void shark_id_dispatch_int32(int id, gint32 val);void shark_id_dispatch_uint32(int id, guint32 val);void shark_id_dispatch_uint64(int id, guint64 val);void shark_id_dispatch_double(int id, double val);#define fvalue_set(i ...) do&#123; \ shark_id_dispatch_string(fi-&gt;hfinfo-&gt;id, fvalue_set(i)); \&#125;while(0) \#define fvalue_set_uinteger(i ...) do&#123; \ shark_id_dispatch_uint32(fi-&gt;hfinfo-&gt;id, fvalue_set_uinteger(i)); \&#125;while(0) \#define fvalue_set_sinteger(i ...) do&#123; \ shark_id_dispatch_int32(fi-&gt;hfinfo-&gt;id, fvalue_set_sinteger(i)); \&#125;while(0) \#define fvalue_set_integer64(i ...) do&#123; \ shark_id_dispatch_uint64(fi-&gt;hfinfo-&gt;id, fvalue_set_integer64(i)); \&#125;while(0) \#define fvalue_set_floating(i ...) do&#123; \ shark_id_dispatch_double(fi-&gt;hfinfo-&gt;id, fvalue_set_floating(i)); \&#125;while(0) \ 原始的fvalue_set等5个函数返回类型为void，我们要修改为接受value的类型，并将valuereturn出来，比如修改fvalue_set为如下 1234567gpointer // 将void换成接受的value的类型fvalue_set(fvalue_t *fv, gpointer value, gboolean already_copied)&#123; g_assert(fv-&gt;ftype-&gt;set_value); fv-&gt;ftype-&gt;set_value(fv, value, already_copied); return value; // 这里是修改的return&#125; 这样，我们就将value直接分类型转给了我们自己声明的shark_id_dispatch_string等5个方法, 我们可以在另外一个动态库中实现这5个方法，然后修改Makefile链接起来，这样以后只需要修改我们自己的so就能达到修改逻辑的目的 tricky的地方注意到了么，我们没有name，没有abbrev，而只有一个fi-&gt;hfinfo-&gt;id。这个id其实是thark编译的时候根据各个解包器生成的固定的id，如果在proto.c的proto_register_field_init函数return之前添加一行 1printf("proto_register_field_init: %d-&gt;%s\n", hfinfo-&gt;id, hfinfo-&gt;abbrev); 编译执行开始，总能看到id和abbrev的固定映射关系，比如： 12345proto_register_field_init: 20587-&gt;dns.idproto_register_field_init: 20588-&gt;dns.qry.typeproto_register_field_init: 20589-&gt;dns.qry.classproto_register_field_init: 20590-&gt;dns.qry.classproto_register_field_init: 20591-&gt;dns.qry.qu 因此，这样的映射表只需要知道，然后就完全可以根据id来做自己的逻辑了。 Wish you happy, go nuts!]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo+next主题的markdown示范样例备忘]]></title>
      <url>%2F1984%2F12%2F02%2Fmarkdown%2Bexample%2F</url>
      <content type="text"><![CDATA[12345678link: - http://cybatk.com/ &lt;!-- 修改title的链接 --&gt;photos: - http://wx3.sinaimg.cn/mw690/6c4e11d1ly1fdwwlmkoehj212w1mc12f.jpg - http://wx4.sinaimg.cn/mw690/6c4e11d1ly1fdwwlk2kg9j212w1mcgux.jpg - http://wx1.sinaimg.cn/mw690/6c4e11d1ly1fdwwlnrrrhj212w1mc7cg.jpg--- 这篇blog没有干货，所以一上来就得有点趣味 123&#123;% centerquote %&#125;这篇blog没有干货，所以一上来就得有点趣味&#123;% endcenterquote %&#125; !!!: hexo tag doc @xuy1202hexo.io/docs/tag-plugins.html Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. David LevithanWide Awake Every interaction is both precious and an opportunity to delight. Seth GodinWelcome to Island Marketing Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem. Head1This is an H2Head2sub titlesub title This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. default primary success info warning danger 123456&#123;% note default %&#125; default &#123;% endnote %&#125;&#123;% note primary %&#125; primary &#123;% endnote %&#125;&#123;% note success %&#125; success &#123;% endnote %&#125;&#123;% note info %&#125; info &#123;% endnote %&#125;&#123;% note warning %&#125; warning &#123;% endnote %&#125;&#123;% note danger %&#125; danger &#123;% endnote %&#125;]]></content>
    </entry>

    
  
  
</search>
